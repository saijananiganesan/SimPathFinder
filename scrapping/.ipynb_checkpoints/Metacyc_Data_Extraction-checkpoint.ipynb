{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pickle\n",
    "from re import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pathways=['Activation-Inactivation-Interconversion',\n",
    "          'Bioluminescence',\n",
    "          'Biosynthesis',\n",
    "          'Degradation',\n",
    "          'Detoxification',\n",
    "          'Energy-Metabolism',\n",
    "          'Glycan-Pathways',\n",
    "          'Macromolecule-Modification',\n",
    "         'Metabolic-Clusters',\n",
    "         'Super-Pathways']\n",
    "Pathways_dict={i:j for i,j in enumerate(Pathways)}\n",
    "weblink='https://biocyc.org/META/NEW-IMAGE?object='\n",
    "weblink_child=\"https://biocyc.org\"\n",
    "p_dict={i:[] for i in Pathways}\n",
    "e_dict={i:[] for i in Pathways}\n",
    "data_dir='../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get biosynthesis pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pflinks_biosynthesis(weblink,pathway_parent,pathway_child,p_dict,e_dict):\n",
    "    page=requests.get(weblink+pathway_child)\n",
    "    #print (weblink+pathway_child)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    page = soup.find_all('p')\n",
    "    page_text=[p.getText() for p in page]\n",
    "    parent_text=[]\n",
    "    for m,n in enumerate(page_text):\n",
    "        if \"Parent\" in n:\n",
    "            parent_text.append(n.replace('\\n','').replace(' ',''))\n",
    "    #print (parent_text)\n",
    "    mydivs_p=[];mydivs_e=[]\n",
    "    mydivs_p = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"PATHWAY\"},href=True)]\n",
    "    mydivs_e = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"ECOCYC-CLASS\"},href=True)]\n",
    "    [p_dict[pathway_parent].append(i.split('/META/NEW-IMAGE?type=PATHWAY&object=')[1]) for i in mydivs_p]\n",
    "    for i in mydivs_e:\n",
    "        if (i not in e_dict[pathway_parent]) and ('NucleosideandNucleotideDegradation' not in parent_text[0]) and \\\n",
    "        ('Degradation/Utilization/Assimilation'  not in parent_text[0]) and \\\n",
    "        ('Detoxification' not in parent_text[0]) and \\\n",
    "        ('PolysaccharideDegradation' not in parent_text[0]): \n",
    "            #print (\"passes cond\",parent_text)\n",
    "            e_dict[pathway_parent].append(i)\n",
    "            p_dict=get_pflinks_biosynthesis(weblink_child,pathway_parent,i,p_dict,e_dict)     \n",
    "    return p_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_new={};e_new={};p_new[Pathways[2]]=[];e_new[Pathways[2]]=[]\n",
    "biosyn=get_pflinks_biosynthesis(weblink,Pathways[2],Pathways[2],p_new,e_new)\n",
    "print (len(list(set(biosyn['Biosynthesis']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Activation pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pflinks_activation(weblink,pathway_parent,pathway_child,p_dict,e_dict):\n",
    "    page=requests.get(weblink+pathway_child)\n",
    "    #print (weblink+pathway_child)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    page = soup.find_all('p')\n",
    "    page_text=[p.getText() for p in page]\n",
    "    parent_text=[]\n",
    "    for m,n in enumerate(page_text):\n",
    "        if \"Parent\" in n:\n",
    "            parent_text.append(n)\n",
    "    par=''.join(parent_text)\n",
    "    mydivs_p=[];mydivs_e=[]\n",
    "    mydivs_p = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"PATHWAY\"},href=True)]\n",
    "    mydivs_e = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"ECOCYC-CLASS\"},href=True)]\n",
    "    [p_dict[pathway_parent].append(i.split('/META/NEW-IMAGE?type=PATHWAY&object=')[1]) for i in mydivs_p]\n",
    "    for i in mydivs_e:\n",
    "        if i not in e_dict[pathway_parent] and 'Nitrogen Containing Glucoside Degradation' not in par:\n",
    "            #print (\"i\",i)\n",
    "            #print (\"par\",parent_text)\n",
    "            e_dict[pathway_parent].append(i)\n",
    "            p_dict=get_pflinks_activation(weblink_child,pathway_parent,i,p_dict,e_dict)\n",
    "    return p_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "p_new={};e_new={};p_new[Pathways[0]]=[];e_new[Pathways[0]]=[]\n",
    "act=get_pflinks_activation(weblink,Pathways[0],Pathways[0],p_new,e_new)\n",
    "print (len(list(set(act['Activation-Inactivation-Interconversion']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Bioluminescence pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pflinks_bio(weblink,pathway_parent,pathway_child,p_dict,e_dict):\n",
    "    page=requests.get(weblink+pathway_child)\n",
    "    #print (weblink+pathway_child)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    page = soup.find_all('p')\n",
    "    page_text=[p.getText() for p in page]\n",
    "    parent_text=[]\n",
    "    for m,n in enumerate(page_text):\n",
    "        if \"Parent\" in n:\n",
    "            parent_text.append(n)\n",
    "    par=''.join(parent_text)\n",
    "    mydivs_p=[];mydivs_e=[]\n",
    "    mydivs_p = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"PATHWAY\"},href=True)]\n",
    "    mydivs_e = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"ECOCYC-CLASS\"},href=True)]\n",
    "    [p_dict[pathway_parent].append(i.split('/META/NEW-IMAGE?type=PATHWAY&object=')[1]) for i in mydivs_p]\n",
    "    for i in mydivs_e:\n",
    "        if i not in e_dict[pathway_parent]:\n",
    "            #print (\"i\",i)\n",
    "            #print (\"par\",parent_text)\n",
    "            e_dict[pathway_parent].append(i)\n",
    "            p_dict=get_pflinks_bio(weblink_child,pathway_parent,i,p_dict,e_dict)\n",
    "    return p_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "p_new={};e_new={};p_new[Pathways[1]]=[];e_new[Pathways[1]]=[]\n",
    "biol=get_pflinks_bio(weblink,Pathways[1],Pathways[1],p_new,e_new)\n",
    "print (len(list(set(biol['Bioluminescence']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Degradation pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pflinks_deg(weblink,pathway_parent,pathway_child,p_dict,e_dict):\n",
    "    page=requests.get(weblink+pathway_child)\n",
    "    #print (weblink+pathway_child)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    page = soup.find_all('p')\n",
    "    page_text=[p.getText() for p in page]\n",
    "    parent_text=[]\n",
    "    for m,n in enumerate(page_text):\n",
    "        if \"Parent\" in n:\n",
    "            parent_text.append(n.replace('\\n','').replace(' ',''))\n",
    "    #print (parent_text)\n",
    "    mydivs_p=[];mydivs_e=[]\n",
    "    mydivs_p = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"PATHWAY\"},href=True)]\n",
    "    mydivs_e = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"ECOCYC-CLASS\"},href=True)]\n",
    "    [p_dict[pathway_parent].append(i.split('/META/NEW-IMAGE?type=PATHWAY&object=')[1]) for i in mydivs_p]\n",
    "    for i in mydivs_e:\n",
    "        if (i not in e_dict[pathway_parent]) and ('Detoxification' not in parent_text[0]) and \\\n",
    "         ('Activation/Inactivation/Interconversion' not in parent_text[0]) and \\\n",
    "        ('GenerationofPrecursorMetabolitesandEnergy' not in parent_text[0]) and \\\n",
    "         ('Biosynthesis' not in parent_text[0]):\n",
    "        #('PolysaccharideDegradation' not in parent_text[0]): \n",
    "            #print (\"passes cond\",parent_text)\n",
    "            e_dict[pathway_parent].append(i)\n",
    "            p_dict=get_pflinks_deg(weblink_child,pathway_parent,i,p_dict,e_dict)     \n",
    "    return p_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1175\n"
     ]
    }
   ],
   "source": [
    "p_new={};e_new={};p_new[Pathways[3]]=[];e_new[Pathways[3]]=[]\n",
    "deg=get_pflinks_deg(weblink,Pathways[3],Pathways[3],p_new,e_new)\n",
    "print (len(list(set(deg['Degradation']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Metabolic Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pflinks_clus(weblink,pathway_parent,pathway_child,p_dict,e_dict):\n",
    "    page=requests.get(weblink+pathway_child)\n",
    "    print (weblink+pathway_child)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    page = soup.find_all('p')\n",
    "    page_text=[p.getText() for p in page]\n",
    "    parent_text=[]\n",
    "    for m,n in enumerate(page_text):\n",
    "        if \"Parent\" in n:\n",
    "            parent_text.append(n.replace('\\n','').replace(' ',''))\n",
    "    print (parent_text)\n",
    "    mydivs_p=[];mydivs_e=[]\n",
    "    mydivs_p = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"PATHWAY\"},href=True)]\n",
    "    mydivs_e = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"ECOCYC-CLASS\"},href=True)]\n",
    "    [p_dict[pathway_parent].append(i.split('/META/NEW-IMAGE?type=PATHWAY&object=')[1]) for i in mydivs_p]\n",
    "    for i in mydivs_e:\n",
    "        if (i not in e_dict[pathway_parent]) and ('Detoxification' not in parent_text[0]) and \\\n",
    "         ('Activation/Inactivation/Interconversion' not in parent_text[0]) and \\\n",
    "        ('GenerationofPrecursorMetabolitesandEnergy' not in parent_text[0]) and \\\n",
    "         ('Biosynthesis' not in parent_text[0]) and \\\n",
    "        ('PolysaccharideDegradation' not in parent_text[0]) and \\\n",
    "           ('Degradation' not in parent_text[0])  : \n",
    "            #print (\"passes cond\",parent_text)\n",
    "            e_dict[pathway_parent].append(i)\n",
    "            p_dict=get_pflinks_clus(weblink_child,pathway_parent,i,p_dict,e_dict)     \n",
    "    return p_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://biocyc.org/META/NEW-IMAGE?object=Metabolic-Clusters\n",
      "['ParentClasses:Pathways']\n",
      "https://biocyc.org/META/class-tree?object=Pathways\n",
      "[]\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "p_new={};e_new={};p_new[Pathways[-2]]=[];e_new[Pathways[-2]]=[]\n",
    "met=get_pflinks_clus(weblink,Pathways[-2],Pathways[-2],p_new,e_new)\n",
    "print (len(list(set(met['Metabolic-Clusters']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get superpathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pflinks_super(weblink,pathway_parent,pathway_child,p_dict,e_dict):\n",
    "    page=requests.get(weblink+pathway_child)\n",
    "    print (weblink+pathway_child)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    page = soup.find_all('p')\n",
    "    page_text=[p.getText() for p in page]\n",
    "    parent_text=[]\n",
    "    for m,n in enumerate(page_text):\n",
    "        if \"Parent\" in n:\n",
    "            parent_text.append(n.replace('\\n','').replace(' ',''))\n",
    "    print (parent_text)\n",
    "    mydivs_p=[];mydivs_e=[]\n",
    "    mydivs_p = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"PATHWAY\"},href=True)]\n",
    "    mydivs_e = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"ECOCYC-CLASS\"},href=True)]\n",
    "    [p_dict[pathway_parent].append(i.split('/META/NEW-IMAGE?type=PATHWAY&object=')[1]) for i in mydivs_p]\n",
    "    for i in mydivs_e:\n",
    "        if (i not in e_dict[pathway_parent]) and ('Detoxification' not in parent_text[0]) and \\\n",
    "         ('Activation/Inactivation/Interconversion' not in parent_text[0]) and \\\n",
    "        ('GenerationofPrecursorMetabolitesandEnergy' not in parent_text[0]) and \\\n",
    "         ('Biosynthesis' not in parent_text[0]) and \\\n",
    "        ('PolysaccharideDegradation' not in parent_text[0]) and \\\n",
    "           ('Degradation' not in parent_text[0])  : \n",
    "            #print (\"passes cond\",parent_text)\n",
    "            e_dict[pathway_parent].append(i)\n",
    "            p_dict=get_pflinks_clus(weblink_child,pathway_parent,i,p_dict,e_dict)     \n",
    "    return p_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://biocyc.org/META/NEW-IMAGE?object=Super-Pathways\n",
      "['ParentClasses:Pathways']\n",
      "https://biocyc.org/META/class-tree?object=Pathways\n",
      "[]\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "p_new={};e_new={};p_new[Pathways[-1]]=[];e_new[Pathways[-1]]=[]\n",
    "sup=get_pflinks_clus(weblink,Pathways[-1],Pathways[-1],p_new,e_new)\n",
    "print (len(list(set(sup['Super-Pathways']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Detoxification pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pflinks_dox(weblink,pathway_parent,pathway_child,p_dict,e_dict):\n",
    "    page=requests.get(weblink+pathway_child)\n",
    "    #print (weblink+pathway_child)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    page = soup.find_all('p')\n",
    "    page_text=[p.getText() for p in page]\n",
    "    parent_text=[]\n",
    "    for m,n in enumerate(page_text):\n",
    "        if \"Parent\" in n:\n",
    "            parent_text.append(n.replace('\\n','').replace(' ',''))\n",
    "    #print (parent_text)\n",
    "    mydivs_p=[];mydivs_e=[]\n",
    "    mydivs_p = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"PATHWAY\"},href=True)]\n",
    "    mydivs_e = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"ECOCYC-CLASS\"},href=True)]\n",
    "    [p_dict[pathway_parent].append(i.split('/META/NEW-IMAGE?type=PATHWAY&object=')[1]) for i in mydivs_p]\n",
    "    for i in mydivs_e:\n",
    "        if (i not in e_dict[pathway_parent]) and ('Degradation/Utilization/Assimilation' not in parent_text[0]):\n",
    "        #('PolysaccharideDegradation' not in parent_text[0]): \n",
    "            #print (\"passes cond\",parent_text)\n",
    "            e_dict[pathway_parent].append(i)\n",
    "            p_dict=get_pflinks_dox(weblink_child,pathway_parent,i,p_dict,e_dict)     \n",
    "    return p_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "p_new={};e_new={};p_new[Pathways[4]]=[];e_new[Pathways[4]]=[]\n",
    "dox=get_pflinks_dox(weblink,Pathways[4],Pathways[4],p_new,e_new)\n",
    "print (len(list(set(dox['Detoxification']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Macromolecular assemblies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pflinks_mac(weblink,pathway_parent,pathway_child,p_dict,e_dict):\n",
    "    page=requests.get(weblink+pathway_child)\n",
    "    #print (weblink+pathway_child)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    page = soup.find_all('p')\n",
    "    page_text=[p.getText() for p in page]\n",
    "    parent_text=[]\n",
    "    for m,n in enumerate(page_text):\n",
    "        if \"Parent\" in n:\n",
    "            parent_text.append(n.replace('\\n','').replace(' ',''))\n",
    "    #print (parent_text)\n",
    "    mydivs_p=[];mydivs_e=[]\n",
    "    mydivs_p = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"PATHWAY\"},href=True)]\n",
    "    mydivs_e = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"ECOCYC-CLASS\"},href=True)]\n",
    "    [p_dict[pathway_parent].append(i.split('/META/NEW-IMAGE?type=PATHWAY&object=')[1]) for i in mydivs_p]\n",
    "    for i in mydivs_e:\n",
    "        if (i not in e_dict[pathway_parent]) :\n",
    "        #('PolysaccharideDegradation' not in parent_text[0]): \n",
    "            #print (\"passes cond\",parent_text)\n",
    "            e_dict[pathway_parent].append(i)\n",
    "            p_dict=get_pflinks_mac(weblink_child,pathway_parent,i,p_dict,e_dict)     \n",
    "    return p_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "p_new={};e_new={};p_new[Pathways[7]]=[];e_new[Pathways[7]]=[]\n",
    "mac=get_pflinks_deg(weblink,Pathways[7],Pathways[7],p_new,e_new)\n",
    "print (len(list(set(mac['Macromolecule-Modification']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get glycan pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pflinks_glycan(weblink,pathway_parent,pathway_child,p_dict,e_dict):\n",
    "    page=requests.get(weblink+pathway_child)\n",
    "    #print (weblink+pathway_child)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    page = soup.find_all('p')\n",
    "    page_text=[p.getText() for p in page]\n",
    "    parent_text=[]\n",
    "    for m,n in enumerate(page_text):\n",
    "        if \"Parent\" in n:\n",
    "            parent_text.append(n.replace('\\n','').replace(' ',''))\n",
    "    #print (parent_text)\n",
    "    mydivs_p=[];mydivs_e=[]\n",
    "    mydivs_p = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"PATHWAY\"},href=True)]\n",
    "    mydivs_e = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"ECOCYC-CLASS\"},href=True)]\n",
    "    [p_dict[pathway_parent].append(i.split('/META/NEW-IMAGE?type=PATHWAY&object=')[1]) for i in mydivs_p]\n",
    "    for i in mydivs_e:\n",
    "        if (i not in e_dict[pathway_parent]) and  ('Detoxification' not in parent_text[0]) and \\\n",
    "            ('Degradation/Utilization/Assimilation' not in parent_text[0]) and \\\n",
    "            ('Biosynthesis' not in parent_text[0]): \n",
    "            #print (\"passes cond\",parent_text)\n",
    "            e_dict[pathway_parent].append(i)\n",
    "            p_dict=get_pflinks_glycan(weblink_child,pathway_parent,i,p_dict,e_dict)     \n",
    "    return p_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pathways' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c3c0d70e0194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0me_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mp_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPathways\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0me_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPathways\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_pflinks_glycan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweblink\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPathways\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPathways\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Glycan-Pathways'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mp_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Pathways' is not defined"
     ]
    }
   ],
   "source": [
    "p_new={};e_new={};p_new[Pathways[6]]=[];e_new[Pathways[6]]=[]\n",
    "gly=get_pflinks_glycan(weblink,Pathways[6],Pathways[6],p_new,e_new)\n",
    "print (len(list(set(gly['Glycan-Pathways']))))\n",
    "p_new.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get energy pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pflinks_energy(weblink,pathway_parent,pathway_child,p_dict,e_dict):\n",
    "    page=requests.get(weblink+pathway_child)\n",
    "    #print (weblink+pathway_child)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    page = soup.find_all('p')\n",
    "    page_text=[p.getText() for p in page]\n",
    "    parent_text=[]\n",
    "    for m,n in enumerate(page_text):\n",
    "        if \"Parent\" in n:\n",
    "            parent_text.append(n.replace('\\n','').replace(' ',''))\n",
    "    #print (parent_text)\n",
    "    mydivs_p=[];mydivs_e=[]\n",
    "    mydivs_p = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"PATHWAY\"},href=True)]\n",
    "    mydivs_e = [a['href'] for a in soup.findAll(\"a\",{\"class\": \"ECOCYC-CLASS\"},href=True)]\n",
    "    [p_dict[pathway_parent].append(i.split('/META/NEW-IMAGE?type=PATHWAY&object=')[1]) for i in mydivs_p]\n",
    "    for i in mydivs_e:\n",
    "        if (i not in e_dict[pathway_parent]) and  ('InorganicNutrientMetabolism' not in parent_text[0]) and \\\n",
    "            ('Degradation' not in parent_text[0]) and \\\n",
    "            ('Biosynthesis' not in parent_text[0]) and \\\n",
    "            ('SulfurCompoundMetabolism' not in parent_text[0] ): \n",
    "            #print (\"passes cond\",parent_text)\n",
    "            e_dict[pathway_parent].append(i)\n",
    "            p_dict=get_pflinks_energy(weblink_child,pathway_parent,i,p_dict,e_dict)     \n",
    "    return p_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217\n"
     ]
    }
   ],
   "source": [
    "p_new={};e_new={};p_new[Pathways[5]]=[];e_new[Pathways[5]]=[]\n",
    "ener=get_pflinks_energy(weblink,Pathways[5],Pathways[5],p_new,e_new)\n",
    "print (len(list(set(ener['Energy-Metabolism']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Set A and Set B of pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_classes(all_dicts):\n",
    "    relevant_pwy={}\n",
    "    for i in all_dicts:\n",
    "        relevant_pwy.update(i)\n",
    "    return relevant_pwy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_classes(class_dict):\n",
    "    comb_list=[];new_class_dict={}\n",
    "    for i,j in class_dict.items():\n",
    "        if i=='Bioluminescence':\n",
    "            comb_list=comb_list+j\n",
    "            new_class_dict[i]=j\n",
    "        if i=='Activation-Inactivation-Interconversion':\n",
    "            comb_list=comb_list+j\n",
    "            new_class_dict[i]=j\n",
    "        if i=='Glycan-Pathways':\n",
    "            comb_list=comb_list+j\n",
    "            new_class_dict[i]=j\n",
    "        if i=='Macromolecule-Modification':\n",
    "            j_new=list(set(j)-set(comb_list))\n",
    "            comb_list=comb_list+j_new\n",
    "            new_class_dict[i]=j_new\n",
    "        if i=='Detoxification':\n",
    "            j_new=list(set(j)-set(comb_list))\n",
    "            comb_list=comb_list+j_new\n",
    "            new_class_dict[i]=j_new\n",
    "        if i=='Degradation':\n",
    "            j_new=list(set(j)-set(comb_list))\n",
    "            comb_list=comb_list+j_new\n",
    "            new_class_dict[i]=j_new\n",
    "        if i=='Biosynthesis':\n",
    "            j_new=list(set(j)-set(comb_list))\n",
    "            comb_list=comb_list+j_new\n",
    "            new_class_dict[i]=j_new\n",
    "            break\n",
    "    return new_class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersection(a,b):\n",
    "    return list(set(a).intersection(set(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pwy_intersection(dictionary_of_interest):\n",
    "    for i,j in dictionary_of_interest.items():\n",
    "        for m,n in dictionary_of_interest.items():\n",
    "            if i !=m:\n",
    "                print (i,m,len(list(set(j).intersection(set(n)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dicts=[act,biol,gly,mac,deg,dox,biosyn]\n",
    "combined_dict=combine_classes(all_dicts)\n",
    "new_combined_dict=clean_classes(combined_dict)\n",
    "check_pwy_intersection(new_combined_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(new_combined_dict, open( \"metacyc_class.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metacyc multilabel dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dicts=[act,biol,gly,ener,mac,deg,dox,biosyn,met,sup]\n",
    "combined_dict=combine_classes(all_dicts)\n",
    "pickle.dump(combined_dict, open(data_dir+ \"metacyc_classes_all.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
